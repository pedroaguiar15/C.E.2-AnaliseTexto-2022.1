---
title: "No Twitter!"
author: "Análise de Texto"
date: '2022-09-05'
output:
  ioslides_presentation: default
  slidy_presentation: default
---


#Analisando textos do Twitter

#O pacote Rtweet 

## Primeiro acesso 
A API do twitter nos disponibilizará os dados que precisamos, mas antes, é necessário obtermos alguns "credenciamentos" para acessá-la: 

> - Consumer Key
> - Consumer Secret
> - Access Token
> - Access Secret


Para isso, basta acessar esse link <https://developer.twitter.com/en/apps> e seguir os passos a partir de "Create an App". Após a primeira solicitação de qualquer função do pacote, o R cobrará suas credenciais. 


---


#O Pacote

Com o pacote rtweet, podemos localizar os últimos tweets feitos com uma palavra de interesse, por default, a função busca os últimos 100 tweets, mas esses parâmetros podem ser alterados. 
*#Atenção!*
O pacote "rtweet" *carrega até 18000 tweets a cada 15 minutos*, para cada usuário, entretanto, se for de interesse o parâmetro "retryonratelimit = TRUE" pode ser utlizado para que mais tweets sejam carregados. O R esperará o tempo para que a próxima consulta possa ser feita! 


---


##Algumas funções do Rtweet
-Procurando palavras chaves
```{r}
library(rtweet)
library(dplyr)
tweets <- search_tweets("#eleições", 
                        n = 1800,
                        include_rts = FALSE)
```
Também podemos procurar por hastags!
```{r}
tweetseleiçoes <- search_tweets("#eleições",
                                n=10)
```

Podemos agora, localizar no mapa esses tweets!
```{r setup}
tweets_coord <- lat_lng(tweets)
```

```{r}
## plota o mapa do Brasil
library(maps)
par(mar = c(0,0,0,0))
mapa <- map("world", "brazil",  
            fill=T,
            col="grey90",
            lwd = 0.50)
map.cities(country = "Brazil",
           minpop = 1000000, #mínimo da população
           pch=19, 
           cex=0.5)
with(tweets_coord,
     points(lng, lat, 
            pch = 20, #o símbolo
            cex = 0.75, #tamanho do símbolo
            col = rgb(1, 0.6, .7, .8))) # função mais sofisticada para escolha da cor
```


---


#Coletando, limpando e analisando tweets 

```{r}
texto = tweets$full_text
```

```{r}
#limpando usando a função tm (textminning)
library(tm)
texto <- texto        %>%
  (removeNumbers)     %>%
  (removePunctuation) %>%
  (stripWhitespace)
```



---


#Criando o Corpus
-Corpus = texto + metadados 

```{r}
dados <- Corpus(VectorSource(texto))
dados <- tm_map(dados, 
               content_transformer(tolower))
dados<- tm_map(dados, 
               removeWords, 
               stopwords('pt')) 
```
---



```{r}
amatrix<- TermDocumentMatrix(dados)  # Matriz de Palvras frequentes 
amatrix<-removeSparseTerms(amatrix, 0.98)
matrix <-as.matrix(amatrix)
matrix<-sort(rowSums(matrix), decreasing = TRUE)
df_tweets<-data.frame(Palavras = names(matrix),
                    Frequencia = matrix) 
```

---


Frequência Palavras 
```{r}
library(ggplot2)
library(dplyr)
ggplot(subset(df_tweets,
              Frequencia > 300),
       eleicoes=eleições) +
  aes(y = Palavras, x = Frequencia, fill = Palavras) +
  geom_bar(stat = "identity")+
    labs(title="Palavras mais citadas nos últimos dias em #eleições2022", 
        subtitle="Dados retirados do Twitter com o pacote rtweet",
        caption="Source: mpg")
```


```{r}
library(wordcloud)
library(wordcloud2)

wordcloud(df_tweets$Palavra,
          df_tweets$Frequencia,
          min.freq = 50,
          random.order=FALSE,
           color = "skyblue")
```

```{r}

wordcloud2(df_tweets[1:50, ],
           size = 2, 
           color = "skyblue", 
           backgroundColor = "black")
```
#Funções "gget_timeline + ts_plot

-get_timeline(c("usuario1","usuario2","usuario3")) 
-ts_plot + group_by

```{r}
library(dplyr)
jair <- get_timeline("jairbolsonaro", n = 100)
lula <- get_timeline("LulaOficial", n = 100,)
ciro <- get_timeline("cirogomes", n = 100,)

jair <- cbind(jair, users_data(jair)[, c("name", "screen_name")])
lula <- cbind(lula, users_data(lula)[, c("name", "screen_name")])
ciro <- cbind(ciro, users_data(ciro)[, c("name", "screen_name")])
linhatempo <- rbind(jair, lula, ciro)
```


---


```{r}
library(ggplot2)
ts_plot(data = linhatempo,
          by = "2 days") +
  theme_classic() +
  labs(
    x = NULL, 
    y = NULL,
    title = "Frequencia de Tweets pelo presidenciais nos últimos dias ",
    subtitle = "Tweets a cada 2 dias.",
    caption = "\nSource: Dados coletados pela API do Twitter"
  )
```

#API GOOGLE MAPS 
- chave de autenticação
- 25.000 requisições gratuitas 

Tweets que sairam do Brasil.
```{r}
nobrasil <- search_tweets("#rockinrio",
                          geocode = lookup_coords("brazil"), n = 1000
)
##
```
Tweets em português, enviados dos Estados Unidos 
```{r}
usa<-search_tweets("lang:pt-BR",
              geocode = lookup_coords("usa"), 
              n = 2000
)
```

Stream_tweets
```{r}
bsb <- stream_tweets(lookup_coords("brazil"), 
                       timeout = 5)
```

E as trends?
```{r, echo=TRUE, }
viral <- get_trends("brazil")
View(viral$trend)
```


---


#Get_...()

> - get_favorites 
> - get_followers 
> - get_friends 
> - get_mentions 
> - get_retweets 
> - get_timeline 
> - get_token 
> - get_trends


---

Lookup! 

> - lookup_coords 
> - lookup_friendships 
> - lookup_tweets 
> - lookup_users
